{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppression des didascalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import spacy\n",
    "from forced_alignment import ForcedAlignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Json File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de phrases annotées : 1510\n"
     ]
    }
   ],
   "source": [
    "json_file = \"/vol/work1/bergoend/didascalies.jsonl\"\n",
    "\n",
    "with open(json_file, 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "    \n",
    "print(\"Nombre de phrases annotées :\", len(json_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "forced_alignment = ForcedAlignment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'un dictionnaire de corrections\n",
    "\n",
    "- Chargement de l'alignement forcé correspondant à l'épisode en cours\n",
    "- Recherche de la phrase annotée à l'aide du contexte gauche\n",
    "- Recherche des mots à supprimer (chaque mot à supprimer a un identifiant qui est sa position dans la phrase affichée dans Prodigy)\n",
    "- Stockage : {(épisode, index de la phrase annotée dans l'alignement forcé) : (phrase affichée dans Prodigy, correction à apporter)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode : 24.Season01.Episode02\n",
      "Tokens affichés dans Prodigy : ['Get', 'back', '!', 'RICK', ':', 'Do', \"n't\", 'be', 'a', 'moron', '!']\n",
      "Phrase sélectionnable dans Prodigy : RICK :\n",
      "Tokens à supprimer : RICK :\n",
      "Nouvelle phrase après correction :  \n",
      "\n",
      "Episode : 24.Season01.Episode02\n",
      "Tokens affichés dans Prodigy : ['et', \"'s\", 'get', 'out', 'of', 'here', '.', 'JACK', ':', 'Take', 'the', 'wall', '.']\n",
      "Phrase sélectionnable dans Prodigy : JACK\n",
      "Tokens à supprimer : JACK\n",
      "Nouvelle phrase après correction :  \n",
      "\n",
      "Episode : 24.Season01.Episode02\n",
      "Tokens affichés dans Prodigy : ['Hello', '?', 'KIM', ':', 'Mom', '?']\n",
      "Phrase sélectionnable dans Prodigy : KIM :\n",
      "Tokens à supprimer : KIM :\n",
      "Nouvelle phrase après correction :  \n",
      "\n",
      "Episode : 24.Season01.Episode02\n",
      "Tokens affichés dans Prodigy : ['She', 'went', 'for', 'a', 'walk', '.', 'KIM', ':', 'We', \"'re\", 'okay']\n",
      "Phrase sélectionnable dans Prodigy : KIM :\n",
      "Tokens à supprimer : KIM :\n",
      "Nouvelle phrase après correction :  \n",
      "\n",
      "Episode : 24.Season01.Episode02\n",
      "Tokens affichés dans Prodigy : ['It', \"'s\", 'better', 'than', 'the', 'truth', '.', 'MAN', ':', 'Did', 'you', 'get', 'the', 'ID', '?']\n",
      "Phrase sélectionnable dans Prodigy : MAN :\n",
      "Tokens à supprimer : MAN :\n",
      "Nouvelle phrase après correction :  \n",
      "\n",
      "Episode : 24.Season01.Episode05\n",
      "Tokens affichés dans Prodigy : ['OK', '.', '(bird', 'flies', 'off', 'Just', 'be', 'cool', '.', 'We', \"'d\", 'like', 'our', 'money', 'now', ',', 'if', 'that', \"'s\", 'like', ',', 'you', 'know', ',', 'OK', '.']\n",
      "Phrase sélectionnable dans Prodigy : (bird flies off Just be cool .\n",
      "Tokens à supprimer : (bird flies off\n",
      "Nouvelle phrase après correction :   Just be cool .\n",
      "\n",
      "Episode : 24.Season01.Episode08\n",
      "Tokens affichés dans Prodigy : ['Sounds', 'like', 'you', \"'re\", 'saying', 'this', \"'cause\", 'something', 'bad', 'will', 'happen', '.', 'TERI', ':', 'No', ',', 'no', '.']\n",
      "Phrase sélectionnable dans Prodigy : TERI :\n",
      "Tokens à supprimer : TERI :\n",
      "Nouvelle phrase après correction :  \n",
      "\n",
      "Episode : 24.Season01.Episode08\n",
      "Tokens affichés dans Prodigy : ['Take', 'them', 'back', '.', 'KIM', ':', 'No', '!', 'No', '!']\n",
      "Phrase sélectionnable dans Prodigy : KIM :\n",
      "Tokens à supprimer : KIM :\n",
      "Nouvelle phrase après correction :  \n",
      "\n",
      "Episode : 24.Season01.Episode24\n",
      "Tokens affichés dans Prodigy : ['Okay', '.', 'REPORTER', ':', 'while', 'eluding', 'two', 'assassination', 'attempts', ',', 'just', 'hours', 'apart', '.']\n",
      "Phrase sélectionnable dans Prodigy : REPORTER :\n",
      "Tokens à supprimer : REPORTER :\n",
      "Nouvelle phrase après correction :  \n",
      "\n",
      "Episode : BattlestarGalactica.Season01.Episode03\n",
      "Tokens affichés dans Prodigy : ['I', 'only', 'committed', 'you', 'to', 'obeying', 'the', 'law', '.', 'Roslin', ':', 'You', 'are', 'not', 'authorized', 'to', 'make', 'any', 'deal', '...']\n",
      "Phrase sélectionnable dans Prodigy : Roslin :\n",
      "Tokens à supprimer : Roslin :\n",
      "Nouvelle phrase après correction :  \n",
      "\n",
      "Episode : BattlestarGalactica.Season01.Episode10\n",
      "Tokens affichés dans Prodigy : ['And', 'pray', 'were', 'lucky', 'enough', 'to', 'find', 'a', 'habitable', 'planet', '.', 'snakes-', 'hissing', 'Madam', 'President', ',', 'without', 'fuel', 'to', 'take', 'even', 'the', 'most', 'basic', 'evasive', 'maneuver--']\n",
      "Phrase sélectionnable dans Prodigy : snakes-\n",
      "Tokens à supprimer : snakes-\n",
      "Nouvelle phrase après correction :  \n",
      "\n",
      "Episode : BattlestarGalactica.Season01.Episode10\n",
      "Tokens affichés dans Prodigy : ['How', 's', 'it', 'going', ',', 'Crash', '?', 'Giggling', 'Oh', ',', 'you', 're', 'so', 'cute', '.']\n",
      "Phrase sélectionnable dans Prodigy : Giggling\n",
      "Tokens à supprimer : Giggling\n",
      "Nouvelle phrase après correction :  \n",
      "\n",
      "Episode : BattlestarGalactica.Season01.Episode10\n",
      "Tokens affichés dans Prodigy : ['the', 'Cylons', 'will', 'be', 'guarding', 'that', 'one', 'too', '.', 'Apollo', ':', 'So', 'we', 'send', 'the', 'raptors', 'out', 'farther', ',', '10', ',', '15', 'jumps', '.']\n",
      "Phrase sélectionnable dans Prodigy : Apollo :\n",
      "Tokens à supprimer : Apollo :\n",
      "Nouvelle phrase après correction :  \n",
      "\n",
      "Episode : BattlestarGalactica.Season01.Episode10\n",
      "Tokens affichés dans Prodigy : ['Tally', ',', '90', '+', 'headed', 'deacon', ',', 'speed', ':', '250', '.', 'Crashdown', ':', 'The', 'Cylons', 'have', 'seen', 'the', 'freighter', '.']\n",
      "Phrase sélectionnable dans Prodigy : Crashdown :\n",
      "Tokens à supprimer : Crashdown :\n",
      "Nouvelle phrase après correction :  \n",
      "\n",
      "Episode : BattlestarGalactica.Season01.Episode10\n",
      "Tokens affichés dans Prodigy : ['Gaeta', ',', 'launch', 'strike', 'force', 'one', '.', 'Gaeta', ':', 'Aye', ',', 'sir', '.']\n",
      "Phrase sélectionnable dans Prodigy : Gaeta :\n",
      "Tokens à supprimer : Gaeta :\n",
      "Nouvelle phrase après correction :  \n",
      "\n",
      "Episode : BattlestarGalactica.Season01.Episode11\n",
      "Tokens affichés dans Prodigy : ['.', '6', 'gasps.]', 'What', 'the', 'hell', 'is', 'going', 'on', '?']\n",
      "Phrase sélectionnable dans Prodigy : 6 gasps.]\n",
      "Tokens à supprimer : 6 gasps.]\n",
      "Nouvelle phrase après correction :  \n",
      "\n",
      "Episode : BattlestarGalactica.Season01.Episode12\n",
      "Tokens affichés dans Prodigy : ['Raptor', 'one', ',', 'last', 'visual', 'contact', 'was', 'seen', 'under', 'powered', 'flight', ',', 'heading', 'toward', 'the', 'surface', '.', 'Adama', ':', 'We', 'need', 'a', 'way', 'to', 'take', 'out', 'the', 'baseship', 'before', 'we', 'can', 'attempt', 'a', 'rescue', '.']\n",
      "Phrase sélectionnable dans Prodigy : Adama :\n",
      "Tokens à supprimer : Adama :\n",
      "Nouvelle phrase après correction :  \n",
      "\n",
      "Episode : BattlestarGalactica.Season01.Episode05\n",
      "Tokens affichés dans Prodigy : ['Are', 'you', '...', 'alive', '?', 'And', 'she', 'keeps', 'going', 'at', 'it', 'with', 'the', 'knife', '.', 'What', 'the', 'hell', 'happened', 'this', 'time', ',', 'Captain', '?']\n",
      "Phrase sélectionnable dans Prodigy : And she keeps going at it with the knife .\n",
      "Tokens à supprimer : And she keeps going at it with the knife .\n",
      "Nouvelle phrase après correction :  \n",
      "\n",
      "Episode : BattlestarGalactica.Season01.Episode11\n",
      "Tokens affichés dans Prodigy : ['Kara', ',', 'give', 'me', 'that', '.', 'SECURITY', 'Thank', 'you', ',', 'sir', '.']\n",
      "Phrase sélectionnable dans Prodigy : SECURITY\n",
      "Tokens à supprimer : SECURITY\n",
      "Nouvelle phrase après correction :  \n"
     ]
    }
   ],
   "source": [
    "# modifications for the new transcript\n",
    "corrections = {}\n",
    "n_corrections = 0\n",
    "\n",
    "for el in json_list:\n",
    "    \n",
    "    # read json\n",
    "    el = json.loads(el)\n",
    "    \n",
    "    # find elements to delete\n",
    "    if el['answer'] == 'reject':\n",
    "        try:\n",
    "            # displayed tokens in Prodigy (left and right context + sentence)\n",
    "            tokens = el['tokens']            \n",
    "            # words to delete\n",
    "            delete = el['spans']\n",
    "            meta = el['meta']\n",
    "            # processed sentence in Prodigy\n",
    "            initial_sent = el['sentence']\n",
    "            # context (disabled)\n",
    "            left = el['left']\n",
    "            right = el['right']\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "        # token list of tokens displayed in Prodigy\n",
    "        token_list = [token['text'] for token in tokens]\n",
    "        print(\"\\nEpisode :\", meta['episode'])\n",
    "        print(\"Tokens affichés dans Prodigy :\", token_list)\n",
    "\n",
    "        # load forced alignment\n",
    "        episode = meta['episode'].split('.')        \n",
    "        aligned = f\"/vol/work1/bergoend/pyannote-db-plumcot/Plumcot/data/{episode[0]}/forced-alignment/{meta['episode']}.aligned\"       \n",
    "        transcript = forced_alignment(aligned)      \n",
    "        sentences = list(transcript.sents)\n",
    "\n",
    "        for sentence in sentences:\n",
    "\n",
    "            # find left context\n",
    "            if str(sentence) == left:\n",
    "                \n",
    "                # find initial sentence\n",
    "                center = sentences[sentences.index(sentence) +1]\n",
    "                index = sentences.index(center)\n",
    "\n",
    "                if str(center) == initial_sent:\n",
    "                    print(\"Phrase sélectionnable dans Prodigy :\", str(center))\n",
    "                    # delete\n",
    "                    for dic in delete:\n",
    "                        if dic['label'] == \"DELETE\":                            \n",
    "                            n_corrections +=1\n",
    "                            # find the words group to delete in initial sentence\n",
    "                            to_delete = \" \".join(token_list[dic['token_start']:dic['token_end']+1])\n",
    "                            print(\"Tokens à supprimer :\", to_delete)\n",
    "                            \n",
    "                            # delete didascalie\n",
    "                            if to_delete in initial_sent:                                \n",
    "                                new_sent = initial_sent.replace(to_delete, ' ')\n",
    "                                print(\"Nouvelle phrase après correction :\", new_sent)\n",
    "                                corrections[(meta['episode'], index)] = (center, new_sent)\n",
    "\n",
    "                # continue until initial sentence is found\n",
    "                else:\n",
    "                    continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('24.Season01.Episode02', 206): (RICK :, ' '), ('24.Season01.Episode02', 343): (JACK, ' '), ('24.Season01.Episode02', 534): (KIM :, ' '), ('24.Season01.Episode02', 553): (KIM :, ' '), ('24.Season01.Episode02', 35): (MAN :, ' '), ('24.Season01.Episode05', 763): ((bird flies off Just be cool ., '  Just be cool .'), ('24.Season01.Episode08', 513): (TERI :, ' '), ('24.Season01.Episode08', 604): (KIM :, ' '), ('24.Season01.Episode24', 547): (REPORTER :, ' '), ('BattlestarGalactica.Season01.Episode03', 621): (Roslin :, ' '), ('BattlestarGalactica.Season01.Episode10', 11): (snakes-, ' '), ('BattlestarGalactica.Season01.Episode10', 27): (Giggling, ' '), ('BattlestarGalactica.Season01.Episode10', 61): (Apollo :, ' '), ('BattlestarGalactica.Season01.Episode10', 323): (Crashdown :, ' '), ('BattlestarGalactica.Season01.Episode10', 329): (Gaeta :, ' '), ('BattlestarGalactica.Season01.Episode11', 2): (6 gasps.], ' '), ('BattlestarGalactica.Season01.Episode12', 369): (Adama :, ' '), ('BattlestarGalactica.Season01.Episode05', 192): (And she keeps going at it with the knife ., ' '), ('BattlestarGalactica.Season01.Episode11', 144): (SECURITY, ' ')}\n",
      "Nombre d'annotations contenant des suppressions : 19\n",
      "Nombre de corrections prises en compte : 19\n"
     ]
    }
   ],
   "source": [
    "print(corrections)\n",
    "print(\"Nombre d'annotations contenant des suppressions :\", n_corrections)\n",
    "print(\"Nombre de corrections prises en compte :\", len(corrections))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Episodes to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes contenant des éléments à supprimer :\n",
      "\n",
      " {'BattlestarGalactica.Season01.Episode11', '24.Season01.Episode24', '24.Season01.Episode08', 'BattlestarGalactica.Season01.Episode05', 'BattlestarGalactica.Season01.Episode03', 'BattlestarGalactica.Season01.Episode10', 'BattlestarGalactica.Season01.Episode12', '24.Season01.Episode05', '24.Season01.Episode02'}\n"
     ]
    }
   ],
   "source": [
    "episode_list = set([el[0] for el in corrections])\n",
    "print(\"Episodes contenant des éléments à supprimer :\\n\\n\", episode_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ecriture des nouveaux fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/vol/work1/bergoend/pyannote-db-plumcot/Plumcot/data/\"\n",
    "\n",
    "for episode in episode_list:\n",
    "    \n",
    "    # load forced alignment\n",
    "    aligned = path + f\"{episode.split('.')[0]}/forced-alignment/{episode}.aligned\"    \n",
    "    transcript = forced_alignment(aligned)      \n",
    "    sentences = list(transcript.sents)\n",
    "    sentences_str = [str(sentence) for sentence in sentences]\n",
    "\n",
    "    # modifications for the current episode\n",
    "    corrects = []\n",
    "    \n",
    "    for key, val in corrections.items():        \n",
    "        if key[0] == episode:\n",
    "            corrects.append((key[1],val))\n",
    "            \n",
    "    # correct sentences\n",
    "    for idx, s in enumerate(sentences_str):\n",
    "        # for the current sentence, find the modification to afford\n",
    "        for el in corrects:\n",
    "            # if sentence's index equals index in corrections (current episode)            \n",
    "            if idx == el[0]:\n",
    "                # correct the sentence\n",
    "                sentences_str[el[0]] = el[1][1]\n",
    "\n",
    "    # write new file\n",
    "    name = f\"correct_{episode}.txt\"\n",
    "    with open(name, 'w') as f:\n",
    "        writer = f        \n",
    "        for sentence, str_s in zip(sentences, sentences_str):\n",
    "            # do not write corrections if they are white spaces\n",
    "            if str_s != ' ':                \n",
    "                writer.write(sentence._.speaker + ' ' + str_s + '\\n')\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vérifier si on ne perd pas d'information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in episode_list:\n",
    "    \n",
    "    aligned = path + f\"{episode.split('.')[0]}/forced-alignment/{episode}.aligned\"\n",
    "    \n",
    "    transcript = forced_alignment(aligned)      \n",
    "    sentences = list(transcript.sents)\n",
    "    sentences_str = [str(sentence) for sentence in sentences]\n",
    "    \n",
    "    name = f\"verif_{episode}.txt\"\n",
    "    with open(name, 'w') as f:\n",
    "        writer = f        \n",
    "        for sentence in sentences:\n",
    "              \n",
    "            writer.write(sentence._.speaker + ' ' + str(sentence) + '\\n')\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
